# Single Threaded Ray Tracer
![Java 8](https://img.shields.io/badge/Java-1.8u92-blue.svg)

An adaptation of my earlier Swift 2.3 and Python 3.6 Ray tracer in Java 1.8 for use with the Texas A&M University class CSCE 435.

![1920x1080 5000](https://user-images.githubusercontent.com/5340992/29982845-f7426c14-8f18-11e7-86e5-1c8f0db2a72b.png)

## About Ray Tracing
[Ray tracing](https://en.wikipedia.org/wiki/Ray_tracing_(graphics)) is the name for a simple and thorough family of image synthesis processes meant to simulate lights, objects, and cameras. In fact, it's inverted to a camera; a normal camera takes a picture as the result of captureing the "light rays" generated by light sources, bounced around in a scene, and then coming through the camera aperture. A ray tracer starts with the "aperture," generating "vision rays" from the "sensor" and shooting them out into the scene to interact with the objects.

Ray tracing generally involves many vector calculations and approximations of the way light behaves in a system. Often a single pixel is the result of thousands of samples, each of which can recurse and propagate multiple times, making the result look accurate. This accuracy comes with a very high price: lots of computing time. Because of this, it's generally favorable to build implementations in languages that can optimize for speed. Java is not always the fastest, but it is a very capable language, and the parameters of the scene we'll be tracing will be relatively simple.

### The Life of a Ray
A ray starts at our sensor, our camera gives it an origin and direction, and it shoots into the scene. It checks against every object in our scene, finds the nearest object it intersects, and gets the material of the object. The material tells us the color of the object, and how the ray should bounce. Then we recurse with this new bounce ray, tracing it as we did the first. Rays can bounce up to a limit (`Camera.depth`) and by the end one of two things happen: either it hits a light source (we only have one here: the sky), or it keeps hitting objects until the final recursion. If it hits a light source, then it stops and combines all the colors its encountered. If it didn't hit a light source, it returns black and becomes part of a shadow.

We shoot many rays for each pixel, each one originating from slightly different randomized spots in the pixel bounds and combine them in what is known as [supersampling](https://en.wikipedia.org/wiki/Supersampling). Because of the randomization of that and some of the surfaces, the results can be noisy if we're stingy with the sampling. In the picture above, each pixel is the result of 5000 individual rays; this allows for fairly low (but still visible if you're scrupulous) noise on the matte surfaces.

### Put in perspective
The scene scene above is 1920 pixels wide, by 1080 pixels tall. The sampling value was 5000, so the number of samples will be 1920 * 1080 * 5000 = 10,368,000,000. Each sample will cast a ray, and bounce up to 10 times, requiring a new cast each time. Each ray involves calculating the intersection point with every object in the scene (5 quadrics and 1 plane), and then finding the closest. It then calculates other information needed to keep going.

These several *billion* rays took hours. Relatively speaking... that's very slow. Most CPUs today can do billions of calculations per second, single-threaded. A powerful GPU in a modern video game can blow that out of the water in terms of FLOPS.

#### Okay, but why?
3 Main reasons:
* This code is single-threaded.
* Ray tracing techniques are *VERY* expensive relative to modern rasterization techniques (depth buffering).
  * Those very techniques are responsible for how easy it is to implement new features, and how good they look.
* I have not implemented many some understood optimization techniques that would help here, such as [Octrees](https://en.wikipedia.org/wiki/Octree), [Binary Spatial Partitioning Trees](https://en.wikipedia.org/wiki/Binary_space_partitioning), and Shape hierachies. There are many other techniques to speed up ray tracing, but given the simplicity of the objects and scene we're rendering, there's likely little many of them would do.

#### Can it go faster?
Absolutely. There are at least 3 fundamentally different ways I can think of to multi-thread the application. This is actually quite open-ended.
